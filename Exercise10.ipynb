{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZEtCzrtc5Fg"
      },
      "source": [
        "# Random Forest Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oIU0H7BK0IRN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8k-G5hDc_fG"
      },
      "source": [
        "In this exercise we will be tuning the RandomForest hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uYSnd8idHU-"
      },
      "source": [
        "Satrt by Importing useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x6Z64ijEc0rI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH-8MhezdL5F"
      },
      "source": [
        "Reading the data which is included in the 'data_banknote_authentication.csv' file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zif6K2TM0IRP",
        "outputId": "54a1c367-d0aa-4d29-9ef1-72de0f738878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Variance_Wavelet  Skewness_Wavelet  Curtosis_Wavelet  Image_Entropy  Class\n",
            "0           3.62160            8.6661           -2.8073       -0.44699      0\n",
            "1           4.54590            8.1674           -2.4586       -1.46210      0\n",
            "2           3.86600           -2.6383            1.9242        0.10645      0\n",
            "3           3.45660            9.5228           -4.0112       -3.59440      0\n",
            "4           0.32924           -4.4552            4.5718       -0.98880      0\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Read the dataset\n",
        "df = pd.read_csv(\"/content/data_banknote_authentication.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGHtoilMddi1"
      },
      "source": [
        "Diving the data into features and labels (X and y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Db0NdvJedk18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615be5b7-acf3-41c1-ad7a-5f4375c78ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X):\n",
            "   Variance_Wavelet  Skewness_Wavelet  Curtosis_Wavelet  Image_Entropy\n",
            "0           3.62160            8.6661           -2.8073       -0.44699\n",
            "1           4.54590            8.1674           -2.4586       -1.46210\n",
            "2           3.86600           -2.6383            1.9242        0.10645\n",
            "3           3.45660            9.5228           -4.0112       -3.59440\n",
            "4           0.32924           -4.4552            4.5718       -0.98880\n",
            "\n",
            "Labels (y):\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Define features (X) and labels (y)\n",
        "X = df.iloc[:, :-1]  # All columns except the last one as features\n",
        "y = df.iloc[:, -1]   # Last column as the target variable\n",
        "\n",
        "print(\"Features (X):\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\nLabels (y):\")\n",
        "print(y.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Vm8Ekrdle1"
      },
      "source": [
        "Splitting the data into train and test parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_hWL54FVeC48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a7de2d-1121-499f-ffb6-5a61280f0be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (1097, 4)\n",
            "Testing set size: (275, 4)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 4: Split data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Testing set size: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGiaxz0seFis"
      },
      "source": [
        "[link text](https://)Use the RandomForest model with a GridSearch to optimize 'n_estimators', 'max_features' and 'criterion' parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B67qgicXeE10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a725592-7761-4d39-abeb-c9ac034d7b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Initialize the RandomForest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
        "    'max_features': ['sqrt', 'log2'],  # Feature selection method\n",
        "    'criterion': ['gini', 'entropy']  # Splitting criteria\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\", best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuDEaG8_edAa"
      },
      "source": [
        "Evaluate the model by displaying a confusion matrix and a classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Acd-A8nBejkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e760070-7dd7-4794-8b08-ce72ca51dd23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[147   1]\n",
            " [  2 125]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       148\n",
            "           1       0.99      0.98      0.99       127\n",
            "\n",
            "    accuracy                           0.99       275\n",
            "   macro avg       0.99      0.99      0.99       275\n",
            "weighted avg       0.99      0.99      0.99       275\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Classification Report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}